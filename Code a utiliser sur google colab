!pip install wfdb scikit-learn matplotlib seaborn

import wfdb
import numpy as np
import pandas as pd
from scipy.signal import butter, filtfilt, find_peaks
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.utils import resample
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import files
uploaded = files.upload()

import zipfile
import os

# Décompression
with zipfile.ZipFile("mit-bih-arrhythmia-database-1.0.0.zip", 'r') as zip_ref:
    zip_ref.extractall("mitdb")

# Vérification du contenu
os.listdir("mitdb")

import wfdb

# Exemple avec l’enregistrement 100
record = wfdb.rdrecord("mitdb/mit-bih-arrhythmia-database-1.0.0/100")
annotation = wfdb.rdann("mitdb/mit-bih-arrhythmia-database-1.0.0/100", 'atr')


import wfdb
import numpy as np
import pandas as pd
from scipy.signal import butter, filtfilt, find_peaks

# Chargement du signal
record_path = 'mitdb/mit-bih-arrhythmia-database-1.0.0/100'
record = wfdb.rdrecord(record_path)
annotation = wfdb.rdann(record_path, 'atr')
signal = record.p_signal[:, 0]
fs = record.fs

# Filtrage passe-bande
def bandpass_filter(data, lowcut=0.5, highcut=40.0, fs=360, order=4):
    nyq = 0.5 * fs
    b, a = butter(order, [lowcut / nyq, highcut / nyq], btype='band')
    return filtfilt(b, a, data)

filtered = bandpass_filter(signal, fs=fs)

# Détection des pics R
peaks, _ = find_peaks(filtered, height=0.5, distance=int(0.2 * fs))

# Extraction des segments + annotations
ann_dict = dict(zip(annotation.sample, annotation.symbol))
window = 108
features = []
labels = []

for i in range(1, len(peaks) - 1):
    r = peaks[i]
    if r - window < 0 or r + window >= len(filtered):
        continue
    segment = filtered[r - window:r + window]
    feat = {
        'amplitude_max': np.max(segment),
        'amplitude_min': np.min(segment),
        'amplitude_range': np.max(segment) - np.min(segment),
        'RR_precedent': (r - peaks[i - 1]) / fs,
        'RR_suivant': (peaks[i + 1] - r) / fs
    }
    label = ann_dict.get(r, 'N')
    features.append(feat)
    labels.append(label)

# DataFrame final
df = pd.DataFrame(features)
df['classe'] = labels
print(df.head())
print("\nRépartition des classes :")
print(df['classe'].value_counts())



from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.utils import resample
import seaborn as sns
import matplotlib.pyplot as plt

# Équilibrage des classes
df_major = df[df['classe'] == 'N']
df_minor = df[df['classe'] == 'A']
df_minor_upsampled = resample(df_minor, replace=True, n_samples=len(df_major), random_state=42)
df_balanced = pd.concat([df_major, df_minor_upsampled])

# Données d'entraînement
X = df_balanced.drop(columns='classe')
y = df_balanced['classe']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Modèle
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

# Évaluation
print("--- Rapport de classification ---")
print(classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)
labels = clf.classes_
plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=labels, yticklabels=labels)
plt.xlabel("Prédit")
plt.ylabel("Réel")
plt.title("Matrice de confusion")
plt.show()

import matplotlib.pyplot as plt

# Portion du signal à afficher (par exemple 5 premières secondes = 5 × 360 échantillons)
nb_samples = 5 * fs
r_peaks_visible = [p for p in peaks if p < nb_samples]

plt.figure(figsize=(15, 4))
plt.plot(filtered[:nb_samples], label='Signal filtré')
plt.plot(r_peaks_visible, filtered[r_peaks_visible], 'ro', label='Pics R')
plt.title("Détection des pics R sur les 5 premières secondes")
plt.xlabel("Échantillons")
plt.ylabel("Amplitude (mV)")
plt.legend()
plt.grid(True)
plt.show()



df.to_csv("features.csv", index=False)
clf_filename = "modele_ecg.pkl"

import joblib
joblib.dump(clf, clf_filename)
files.download(clf_filename)
